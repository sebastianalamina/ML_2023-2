{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8hABvKYnBF1"
   },
   "source": [
    "# 3. Usando el archivo MNIST(mnist_train_small.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QMiguTriyzt"
   },
   "outputs": [],
   "source": [
    "# importamos las lib que usaremos\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import  Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1sB3gkVm4aS"
   },
   "source": [
    "### (a) Realiza una reducción dimensional a dos componentes principales. De todo el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiSZMuLCwlD5"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./sample_data/mnist_train_small.csv', header=None) #Leemos el archivo especificado.\n",
    "data = data.to_numpy() # Pasamos data de pandas a una matriz de numpy.\n",
    "X = data[:,1:]  # Seleccionamos todas las filas y columnas a partir de la segunda columna hasta el final.\n",
    "y = data[:,0]   # Seleccionamos todos los elementos de la primer columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DIMENSIONALIDAD\")\n",
    "print(f\"CSV: {data.shape}\")\n",
    "print(f\"Características: {X.shape}\")\n",
    "print(f\"Labels/Etiquetas: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UZ9yH_Di0sx"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "El argumento n_components=2 en la función PCA indica que se deben seleccionar solamente las dos componentes principales más importantes\n",
    "para la visualización de los datos. En otras palabras, la función PCA(n_components=2) transforma los datos originales en un conjunto de \n",
    "datos de dos dimensiones que mantiene la mayor cantidad de información posible. Esto se logra mediante la proyección de los datos originales\n",
    "en un espacio de dos dimensiones que maximiza la varianza de los datos.\n",
    "'''\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77xb7K3ii17o"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "El resultado de pca.fit_transform(data) es una nueva matriz que representa los datos \n",
    "originales en un espacio de características con una dimensión reducida, en este caso a dos dimensiones.\n",
    "'''\n",
    "X_2d = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"REDUCCIÓN DE DIMENSIONALIDAD\")\n",
    "print(f\"Características reducidas: {X_2d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bflXmFuHpkMH"
   },
   "source": [
    "### (b) Separen los datos a cuyas etiqueta correspondan el 0 y 1. De tal forma que a cada etiqueta correspondan 50 muestras. Para crear un conjunto de entrenamiento.(100 Muestras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTbVDHhz7m1p"
   },
   "outputs": [],
   "source": [
    "# Obtenemos los datos correspondientes a la clase 0 y 1, así como las variables auxiliares para graficar los datos\n",
    "X0 = []\n",
    "X1 = []\n",
    "X0_x,X0_y,X1_x,X1_y = [],[],[],[]\n",
    "for c, x in zip(y,X_2d):\n",
    "  if c==0:\n",
    "    X0.append(x)\n",
    "    X0_x.append(x[0])\n",
    "    X0_y.append(x[1])\n",
    "  elif c==1:\n",
    "    X1.append(x)\n",
    "    X1_x.append(x[0])\n",
    "    X1_y.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Fize3rt-M8i"
   },
   "outputs": [],
   "source": [
    "# Generamos una gráfica, tal que los puntos rojos pertenecen a la clase cero y los azules a la clase uno.\n",
    "plt.scatter(X0_x, X0_y, c=\"r\")\n",
    "plt.scatter(X1_x, X1_y, c=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxVIl2loeK2m"
   },
   "outputs": [],
   "source": [
    "#Funcion auxiliar\n",
    "def getOnesZeros(n):\n",
    "  return np.zeros(n).tolist()+np.ones(n).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXPi_165CmXC"
   },
   "outputs": [],
   "source": [
    "x0 = X0[0:50]\n",
    "x1 = X1[0:50]\n",
    "X = x0+x1\n",
    "y_train = np.array([int(y) for y in getOnesZeros(50)]) # Clases correspondientes al conjunto de entrenamiento.\n",
    "X_train = np.array([x.tolist() for x in X]) # Conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cEdC3pzpzqU"
   },
   "source": [
    "### (c) Gráfica la malla de la clasificación y los puntos de los datos completos de ambas etiquetas. Usando K-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NAarjieQ6P0"
   },
   "outputs": [],
   "source": [
    "# Creamos el modelo KNN y entrenamos\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Creamos una malla de puntos para clasificar\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max), np.arange(y_min, y_max))\n",
    "\n",
    "# Predecimos la clase para cada punto en la malla\n",
    "c = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = knn.predict(c)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Graficamos la malla de clasificación\n",
    "plt.figure(figsize=(8, 6))\n",
    "#plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "plt.pcolormesh(xx, yy, Z, alpha=0.4)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k')\n",
    "plt.title('Malla de Clasificación para KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8--pn_gksFeF"
   },
   "outputs": [],
   "source": [
    "# Función para calcular la distancia euclidiana\n",
    "def euclidean_distance(point, centroid):\n",
    "    return np.sqrt(np.sum((point - centroid)**2))\n",
    "\n",
    "# Generamos el conjunto de prueba\n",
    "x0_test = X0[50:len(X0)]\n",
    "x1_test = X1[50:len(X1)]\n",
    "X_test = np.array(x0_test+x1_test)\n",
    "y_test = np.zeros(len(x0_test)).tolist() + np.ones(len(x1_test)).tolist()\n",
    "y_test = np.array([int(y) for y in y_test])\n",
    "\n",
    "def k_nearest_neighbors(X_train, y_train, X_test, k=3):\n",
    "  #Lista para almacenar las clases asignadas\n",
    "  y_pred = []\n",
    "  X_test = np.array(X_test)\n",
    "\n",
    "  #Iterar sobre cada punto de prueba\n",
    "  for ind in range(X_test.shape[0]):\n",
    "    #Calcular las distancias entre el punto de prueba y todos los puntos de entrenamiento.\n",
    "    distancias = [euclidean_distance(X_test[ind], p_ent ) for p_ent in X_train ]\n",
    "    \n",
    "    #Seleccionar los K puntos más cercanos\n",
    "    K_indices = np.argsort(distancias)[:k] \n",
    "    \n",
    "    # Asignar la clase más frecuente entre los K vecinos más cercanos al punto de prueba\n",
    "    k_nearest_classes = [y_train[idx] for idx in K_indices]\n",
    "    \n",
    "    #Seleccionamos la clase más comun. [(valor,numero_de_repeticiones)]\n",
    "    most_common_clas = Counter(k_nearest_classes).most_common(1)\n",
    "    #Asigamos a la clase más commun.\n",
    "    y_pred.append(most_common_clas[0][0])\n",
    "  return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtgUuTZzunhn"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8),dpi=100)\n",
    "n_vec = 5\n",
    "\n",
    "# Predecir clases para cada punto en X_space\n",
    "y_space_pred = k_nearest_neighbors(X_train, y_train, X_test, k=n_vec)\n",
    "\n",
    "# Graficar los puntos de X_space en diferentes colores según su clase asignada\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_space_pred, cmap='Accent', alpha=.3)#label='Predicted Classes'\n",
    "\n",
    "# Graficar los puntos de entrenamiento y los puntos de prueba en diferentes colores\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='Accent', label='Training Points')\n",
    "#Conjunto de prueba\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1],marker='x', c=y_space_pred,cmap='Accent', label='Test Points')\n",
    "plt.title(f'Vecinos k{n_vec}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Usando `sklearn.metrics.classification_report()`, cree un informe que muestre las principales métricas de clasificación (Precision, Recall, etc). Usando como `X_test` los datos completos del conjunto de datos y como `X_train` El conjunto de datos con las 100 muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def imprimir_reporte(reporte):\n",
    "    for k in report:\n",
    "\n",
    "        if (k == \"0\" or k == \"1\"):\n",
    "            print(f\"Para la clase {k}...\")\n",
    "        elif (k == \"accuracy\"):\n",
    "            print(f\"De manera general, {k}: {report[k]}\\n\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"{k}...\")\n",
    "\n",
    "        for k,v in report[k].items():\n",
    "            print(f\"\\t{k}: {v}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oj5hIsGTulOR",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = k_nearest_neighbors(X_train, y_train, X_test, k=3)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "imprimir_reporte(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Discutan en equipo y den una conclusión de lo que se observa en los datos. ¿Qué puedes decir acerca de las muestras si se usaran 10 muestras por clase? ¿Son muchas o pocas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos los mismos conjuntos pertinentes, pero ahora usando 10 muestras por clase...\n",
    "x0 = X0[0:10]\n",
    "x1 = X1[0:10]\n",
    "X = x0+x1\n",
    "y_train = np.array([int(y) for y in getOnesZeros(10)])\n",
    "X_train = np.array([x.tolist() for x in X])\n",
    "x0_test = X0[10:len(X0)]\n",
    "x1_test = X1[10:len(X1)]\n",
    "X_test = np.array(x0_test+x1_test)\n",
    "y_test = np.zeros(len(x0_test)).tolist() + np.ones(len(x1_test)).tolist()\n",
    "y_test = np.array([int(y) for y in y_test])\n",
    "\n",
    "# Generamos el reporte correspondiente.\n",
    "y_pred = k_nearest_neighbors(X_train, y_train, X_test, k=3)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "imprimir_reporte(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, parece que el número de muestras en el conjunto de entrenamiento no afecta en gran medida la exactitud del modelo basado en KNN. Pues se ven resultados casi idénticos con un número menor de muestras.\n",
    "\n",
    "Podemos decir que, dado el número de clases de clasificación, la cardinalidad del conjunto de entrenamiento no afecta desmedidamente al modelo.\n",
    "\n",
    "Por lo tanto, usar 50 muestras por clases se considera como muchas muestras, mientras que usar 10 se considera suficiente."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
